{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m     \u001b[0mfontManager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fmcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36mjson_load\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \"\"\"\n\u001b[1;32m--> 924\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_json_decode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Akash Sharma\\\\.matplotlib\\\\fontlist-v310.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-72f488f9ddc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontour\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcontour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridspec\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgridspec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\contour.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmcoll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont_manager\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfont_manager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[0mfontManager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fmcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1355\u001b[1;33m     \u001b[0m_rebuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1356\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontManager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_version'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mFontManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36m_rebuild\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_rebuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mfontManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1346\u001b[1;33m     \u001b[0mfontManager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFontManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1347\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fmcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mjson_dump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontManager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fmcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, size, weight)\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0mttffiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindSystemFonts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfindSystemFonts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mttflist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateFontList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mttffiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m         afmfiles = (findSystemFonts(paths, fontext='afm')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36mcreateFontList\u001b[1;34m(fontfiles, fontext)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m                 \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mft2font\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFT2Font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not open font file %s: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "SEED=1234\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(SEED)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from model import *\n",
    "\n",
    "# configure args\n",
    "tf.set_random_seed(SEED)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "# data loading part\n",
    "caseNo = 118\n",
    "weight_4_mag = 100\n",
    "weight_4_ang = 1#2*math.pi/360\n",
    "\n",
    "psse_data = scipy.io.loadmat('dist2_118FASE_data.mat')\n",
    "print(psse_data['inputs'].shape, psse_data['labels'].shape)\n",
    "\n",
    "data_x = psse_data['inputs']\n",
    "data_y = psse_data['labels']\n",
    "\n",
    "# scale the mags,\n",
    "data_y[0:caseNo,:] = weight_4_mag*data_y[0:caseNo,:]\n",
    "data_y[caseNo:,:] = weight_4_ang*data_y[caseNo:,:]\n",
    "\n",
    "\n",
    "# seperate them into training 80%, test 20%\n",
    "split_train = int(0.8*psse_data['inputs'].shape[1])\n",
    "split_val = psse_data['inputs'].shape[1] - split_train #int(0.25*psse_data['inputs'].shape[1])\n",
    "train_x = np.transpose(data_x[:, :split_train])\n",
    "train_y = np.transpose(data_y[:, :split_train])\n",
    "val_x   = np.transpose(data_x[:, split_train:split_train+split_val])\n",
    "val_y   = np.transpose(data_y[:, split_train:split_train+split_val])\n",
    "test_x  = np.transpose(data_x[:, split_train+split_val:])\n",
    "test_y  = np.transpose(data_y[:, split_train+split_val:])\n",
    "\n",
    "print(train_x.shape, val_x.shape)\n",
    "#Train the model\n",
    "input_shape = (train_x.shape[1],)\n",
    "\n",
    "epoch_num = 200\n",
    "psse_model = nn1_8H_psse(input_shape, train_y.shape[1])\n",
    "psse_model.fit(train_x, train_y, epochs=epoch_num, batch_size=64)\n",
    "\n",
    "save_file = '_'.join([str(caseNo), 'nn1_8H_PSSE',\n",
    "                      'epoch', str(epoch_num)]) + '.h5'\n",
    "\n",
    "if not os.path.exists('model_logs'):\n",
    "    os.makedirs('model_logs')\n",
    "save_path = os.path.join('model_logs', save_file)\n",
    "print('\\nSaving model weights to {:s}'.format(save_path))\n",
    "psse_model.save_weights(save_path)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "K.set_learning_phase(0)\n",
    "val_predic = psse_model.predict(val_x)\n",
    "scores = psse_model.evaluate(val_x, val_y)\n",
    "print(\"\\n%s: %.2f%%\" % (psse_model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "#the self.defined distance metric since, to access the distance between predicted and the true\n",
    "print(val_y.shape[0])\n",
    "test_no = 3706\n",
    "def rmse(val_predic, val_y, voltage_distance = np.zeros((test_no,caseNo)), voltage_norm = np.zeros((test_no,1))):\n",
    "    for i in range(test_no):\n",
    "        for j in range(caseNo):\n",
    "            predic_r, predic_i = (1/weight_4_mag)* val_predic[i, j]*math.cos(val_predic[i, j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_predic[i,j]*math.sin(val_predic[i, j+caseNo]*2*math.pi/360)\n",
    "            val_r, val_i = (1/weight_4_mag)*val_y[i,j]*math.cos(val_y[i,j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_y[i][j]*math.sin(val_y[i][j+caseNo]*2*math.pi/360)\n",
    "            voltage_distance[i,j] = (predic_r-val_r)**2 + (predic_i-val_i)**2\n",
    "            #print(i, j, val_predic[i, j], val_predic[i, j+caseNo], val_y[i,j], val_y[i,j+caseNo])\n",
    "        voltage_norm[i,] = (1/caseNo)*np.sqrt(np.sum(voltage_distance[i,:]))\n",
    "    return np.mean(voltage_norm) *100\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(val_predic, val_y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-72f488f9ddc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "SEED=1234\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(SEED)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from model import *\n",
    "\n",
    "# configure args\n",
    "tf.set_random_seed(SEED)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "# data loading part\n",
    "caseNo = 118\n",
    "weight_4_mag = 100\n",
    "weight_4_ang = 1#2*math.pi/360\n",
    "\n",
    "psse_data = scipy.io.loadmat('dist2_118FASE_data.mat')\n",
    "print(psse_data['inputs'].shape, psse_data['labels'].shape)\n",
    "\n",
    "data_x = psse_data['inputs']\n",
    "data_y = psse_data['labels']\n",
    "\n",
    "# scale the mags,\n",
    "data_y[0:caseNo,:] = weight_4_mag*data_y[0:caseNo,:]\n",
    "data_y[caseNo:,:] = weight_4_ang*data_y[caseNo:,:]\n",
    "\n",
    "\n",
    "# seperate them into training 80%, test 20%\n",
    "split_train = int(0.8*psse_data['inputs'].shape[1])\n",
    "split_val = psse_data['inputs'].shape[1] - split_train #int(0.25*psse_data['inputs'].shape[1])\n",
    "train_x = np.transpose(data_x[:, :split_train])\n",
    "train_y = np.transpose(data_y[:, :split_train])\n",
    "val_x   = np.transpose(data_x[:, split_train:split_train+split_val])\n",
    "val_y   = np.transpose(data_y[:, split_train:split_train+split_val])\n",
    "test_x  = np.transpose(data_x[:, split_train+split_val:])\n",
    "test_y  = np.transpose(data_y[:, split_train+split_val:])\n",
    "\n",
    "print(train_x.shape, val_x.shape)\n",
    "#Train the model\n",
    "input_shape = (train_x.shape[1],)\n",
    "\n",
    "epoch_num = 200\n",
    "psse_model = nn1_8H_psse(input_shape, train_y.shape[1])\n",
    "psse_model.fit(train_x, train_y, epochs=epoch_num, batch_size=64)\n",
    "\n",
    "save_file = '_'.join([str(caseNo), 'nn1_8H_PSSE',\n",
    "                      'epoch', str(epoch_num)]) + '.h5'\n",
    "\n",
    "if not os.path.exists('model_logs'):\n",
    "    os.makedirs('model_logs')\n",
    "save_path = os.path.join('model_logs', save_file)\n",
    "print('\\nSaving model weights to {:s}'.format(save_path))\n",
    "psse_model.save_weights(save_path)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "K.set_learning_phase(0)\n",
    "val_predic = psse_model.predict(val_x)\n",
    "scores = psse_model.evaluate(val_x, val_y)\n",
    "print(\"\\n%s: %.2f%%\" % (psse_model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "#the self.defined distance metric since, to access the distance between predicted and the true\n",
    "print(val_y.shape[0])\n",
    "test_no = 3706\n",
    "def rmse(val_predic, val_y, voltage_distance = np.zeros((test_no,caseNo)), voltage_norm = np.zeros((test_no,1))):\n",
    "    for i in range(test_no):\n",
    "        for j in range(caseNo):\n",
    "            predic_r, predic_i = (1/weight_4_mag)* val_predic[i, j]*math.cos(val_predic[i, j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_predic[i,j]*math.sin(val_predic[i, j+caseNo]*2*math.pi/360)\n",
    "            val_r, val_i = (1/weight_4_mag)*val_y[i,j]*math.cos(val_y[i,j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_y[i][j]*math.sin(val_y[i][j+caseNo]*2*math.pi/360)\n",
    "            voltage_distance[i,j] = (predic_r-val_r)**2 + (predic_i-val_i)**2\n",
    "            #print(i, j, val_predic[i, j], val_predic[i, j+caseNo], val_y[i,j], val_y[i,j+caseNo])\n",
    "        voltage_norm[i,] = (1/caseNo)*np.sqrt(np.sum(voltage_distance[i,:]))\n",
    "    return np.mean(voltage_norm) *100\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(val_predic, val_y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-72f488f9ddc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "SEED=1234\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(SEED)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from model import *\n",
    "\n",
    "# configure args\n",
    "tf.set_random_seed(SEED)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "# data loading part\n",
    "caseNo = 118\n",
    "weight_4_mag = 100\n",
    "weight_4_ang = 1#2*math.pi/360\n",
    "\n",
    "psse_data = scipy.io.loadmat('dist2_118FASE_data.mat')\n",
    "print(psse_data['inputs'].shape, psse_data['labels'].shape)\n",
    "\n",
    "data_x = psse_data['inputs']\n",
    "data_y = psse_data['labels']\n",
    "\n",
    "# scale the mags,\n",
    "data_y[0:caseNo,:] = weight_4_mag*data_y[0:caseNo,:]\n",
    "data_y[caseNo:,:] = weight_4_ang*data_y[caseNo:,:]\n",
    "\n",
    "\n",
    "# seperate them into training 80%, test 20%\n",
    "split_train = int(0.8*psse_data['inputs'].shape[1])\n",
    "split_val = psse_data['inputs'].shape[1] - split_train #int(0.25*psse_data['inputs'].shape[1])\n",
    "train_x = np.transpose(data_x[:, :split_train])\n",
    "train_y = np.transpose(data_y[:, :split_train])\n",
    "val_x   = np.transpose(data_x[:, split_train:split_train+split_val])\n",
    "val_y   = np.transpose(data_y[:, split_train:split_train+split_val])\n",
    "test_x  = np.transpose(data_x[:, split_train+split_val:])\n",
    "test_y  = np.transpose(data_y[:, split_train+split_val:])\n",
    "\n",
    "print(train_x.shape, val_x.shape)\n",
    "#Train the model\n",
    "input_shape = (train_x.shape[1],)\n",
    "\n",
    "epoch_num = 200\n",
    "psse_model = nn1_8H_psse(input_shape, train_y.shape[1])\n",
    "psse_model.fit(train_x, train_y, epochs=epoch_num, batch_size=64)\n",
    "\n",
    "save_file = '_'.join([str(caseNo), 'nn1_8H_PSSE',\n",
    "                      'epoch', str(epoch_num)]) + '.h5'\n",
    "\n",
    "if not os.path.exists('model_logs'):\n",
    "    os.makedirs('model_logs')\n",
    "save_path = os.path.join('model_logs', save_file)\n",
    "print('\\nSaving model weights to {:s}'.format(save_path))\n",
    "psse_model.save_weights(save_path)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "K.set_learning_phase(0)\n",
    "val_predic = psse_model.predict(val_x)\n",
    "scores = psse_model.evaluate(val_x, val_y)\n",
    "print(\"\\n%s: %.2f%%\" % (psse_model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "#the self.defined distance metric since, to access the distance between predicted and the true\n",
    "print(val_y.shape[0])\n",
    "test_no = 3706\n",
    "def rmse(val_predic, val_y, voltage_distance = np.zeros((test_no,caseNo)), voltage_norm = np.zeros((test_no,1))):\n",
    "    for i in range(test_no):\n",
    "        for j in range(caseNo):\n",
    "            predic_r, predic_i = (1/weight_4_mag)* val_predic[i, j]*math.cos(val_predic[i, j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_predic[i,j]*math.sin(val_predic[i, j+caseNo]*2*math.pi/360)\n",
    "            val_r, val_i = (1/weight_4_mag)*val_y[i,j]*math.cos(val_y[i,j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_y[i][j]*math.sin(val_y[i][j+caseNo]*2*math.pi/360)\n",
    "            voltage_distance[i,j] = (predic_r-val_r)**2 + (predic_i-val_i)**2\n",
    "            #print(i, j, val_predic[i, j], val_predic[i, j+caseNo], val_y[i,j], val_y[i,j+caseNo])\n",
    "        voltage_norm[i,] = (1/caseNo)*np.sqrt(np.sum(voltage_distance[i,:]))\n",
    "    return np.mean(voltage_norm) *100\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(val_predic, val_y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1234\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c3fa3ccfcb9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 18528) (236, 18528)\n",
      "(14822, 490) (3706, 490)\n",
      "WARNING:tensorflow:From C:\\Users\\Akash Sharma\\Desktop\\Final Year Project\\PSSE-via-DNNs-master\\model.py:25: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/200\n",
      "14822/14822 [==============================] - 14s 976us/step - loss: 6.5920 - mae: 7.0700\n",
      "Epoch 2/200\n",
      "14822/14822 [==============================] - 14s 940us/step - loss: 4.4411 - mae: 4.9172\n",
      "Epoch 3/200\n",
      "14822/14822 [==============================] - 13s 900us/step - loss: 4.5049 - mae: 4.9837\n",
      "Epoch 4/200\n",
      "14822/14822 [==============================] - 13s 885us/step - loss: 2.1879 - mae: 2.64591s -  - ETA: 0s - loss: 2.1777 - mae: 2.63\n",
      "Epoch 5/200\n",
      "14822/14822 [==============================] - 13s 872us/step - loss: 2.8937 - mae: 3.36313s - loss: 3.00 - ETA: 2s - loss: 2.8877 - mae:\n",
      "Epoch 6/200\n",
      "14822/14822 [==============================] - 14s 950us/step - loss: 2.0686 - mae: 2.5257\n",
      "Epoch 7/200\n",
      "14822/14822 [==============================] - 13s 906us/step - loss: 2.4858 - mae: 2.94743s -\n",
      "Epoch 8/200\n",
      "14822/14822 [==============================] - 13s 905us/step - loss: 1.9611 - mae: 2.4154\n",
      "Epoch 9/200\n",
      "14822/14822 [==============================] - 13s 904us/step - loss: 1.9242 - mae: 2.3750\n",
      "Epoch 10/200\n",
      "14822/14822 [==============================] - 13s 905us/step - loss: 1.9493 - mae: 2.4051\n",
      "Epoch 11/200\n",
      "14822/14822 [==============================] - 13s 899us/step - loss: 1.9640 - mae: 2.42310s - loss: 2.02\n",
      "Epoch 12/200\n",
      "14822/14822 [==============================] - 14s 911us/step - loss: 1.7853 - mae: 2.23351s -\n",
      "Epoch 13/200\n",
      "14822/14822 [==============================] - 14s 922us/step - loss: 1.8593 - mae: 2.3124\n",
      "Epoch 14/200\n",
      "14822/14822 [==============================] - 14s 921us/step - loss: 1.8728 - mae: 2.33722s - loss: 1.9563 - mae: 2.4 - ETA:\n",
      "Epoch 15/200\n",
      "14822/14822 [==============================] - 14s 950us/step - loss: 2.5127 - mae: 2.9826\n",
      "Epoch 16/200\n",
      "14822/14822 [==============================] - 14s 963us/step - loss: 1.5063 - mae: 1.9663\n",
      "Epoch 17/200\n",
      "14822/14822 [==============================] - 14s 963us/step - loss: 1.5493 - mae: 2.0205\n",
      "Epoch 18/200\n",
      "14822/14822 [==============================] - 14s 968us/step - loss: 0.8756 - mae: 1.2922\n",
      "Epoch 19/200\n",
      "14822/14822 [==============================] - 15s 988us/step - loss: 0.9035 - mae: 1.3126\n",
      "Epoch 20/200\n",
      "14822/14822 [==============================] - 14s 973us/step - loss: 0.6554 - mae: 1.04731s - lo\n",
      "Epoch 21/200\n",
      "14822/14822 [==============================] - 14s 939us/step - loss: 0.9513 - mae: 1.37100s - loss: 0.9507 - mae: 1.370\n",
      "Epoch 22/200\n",
      "14822/14822 [==============================] - 14s 937us/step - loss: 1.0289 - mae: 1.4493\n",
      "Epoch 23/200\n",
      "14822/14822 [==============================] - 14s 975us/step - loss: 0.5534 - mae: 0.96090s - loss: 0.5524\n",
      "Epoch 24/200\n",
      "14822/14822 [==============================] - 14s 952us/step - loss: 1.4406 - mae: 1.8719\n",
      "Epoch 25/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 1.6214 - mae: 2.0869: 0s - loss: 1.6210 - \n",
      "Epoch 26/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 1.2019 - mae: 1.6429: \n",
      "Epoch 27/200\n",
      "14822/14822 [==============================] - 15s 986us/step - loss: 1.3850 - mae: 1.8543\n",
      "Epoch 28/200\n",
      "14822/14822 [==============================] - 15s 980us/step - loss: 1.2980 - mae: 1.75961s - loss: 1.2989  - ETA: 0s - loss: 1.2973 - mae: - ETA: 0s - loss: 1.2976 - mae: 1.75\n",
      "Epoch 29/200\n",
      "14822/14822 [==============================] - 15s 988us/step - loss: 1.2047 - mae: 1.66050s - loss: 1.2002 \n",
      "Epoch 30/200\n",
      "14822/14822 [==============================] - 14s 953us/step - loss: 0.2892 - mae: 0.59482s - loss: 0.2965 - mae: 0 - ET\n",
      "Epoch 31/200\n",
      "14822/14822 [==============================] - 14s 977us/step - loss: 0.3759 - mae: 0.7401\n",
      "Epoch 32/200\n",
      "14822/14822 [==============================] - 14s 957us/step - loss: 0.4312 - mae: 0.8124\n",
      "Epoch 33/200\n",
      "14822/14822 [==============================] - 14s 964us/step - loss: 0.7601 - mae: 1.1634\n",
      "Epoch 34/200\n",
      "14822/14822 [==============================] - 15s 993us/step - loss: 0.8879 - mae: 1.3000\n",
      "Epoch 35/200\n",
      "14822/14822 [==============================] - 14s 975us/step - loss: 0.6861 - mae: 1.08200s - loss: 0.6875 - mae: 1.08\n",
      "Epoch 36/200\n",
      "14822/14822 [==============================] - 15s 994us/step - loss: 1.1692 - mae: 1.5932\n",
      "Epoch 37/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 1.1763 - mae: 1.6150\n",
      "Epoch 38/200\n",
      "14822/14822 [==============================] - 16s 1ms/step - loss: 0.5598 - mae: 0.9387: 1s - los\n",
      "Epoch 39/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 0.3737 - mae: 0.7403\n",
      "Epoch 40/200\n",
      "14822/14822 [==============================] - 16s 1ms/step - loss: 0.6640 - mae: 1.0603\n",
      "Epoch 41/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 0.4989 - mae: 0.8802\n",
      "Epoch 42/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 0.6092 - mae: 1.0035\n",
      "Epoch 43/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 0.6546 - mae: 1.0480\n",
      "Epoch 44/200\n",
      "14822/14822 [==============================] - 15s 992us/step - loss: 0.7538 - mae: 1.1536\n",
      "Epoch 45/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 1.0391 - mae: 1.4545 - ETA: 1s - loss: 1.09\n",
      "Epoch 46/200\n",
      "14822/14822 [==============================] - 15s 981us/step - loss: 0.3738 - mae: 0.73829s - loss: 0.3198 - mae: 0.668 - ETA: 9s - loss:  - ETA: 0s - loss: 0.373\n",
      "Epoch 47/200\n",
      "14822/14822 [==============================] - 15s 991us/step - loss: 0.3845 - mae: 0.7566\n",
      "Epoch 48/200\n",
      "14822/14822 [==============================] - 14s 978us/step - loss: 0.4060 - mae: 0.7777\n",
      "Epoch 49/200\n",
      "14822/14822 [==============================] - 14s 968us/step - loss: 0.4096 - mae: 0.78265s - loss: 0.3934 - mae: 0.757 - ETA: 5s - los - ETA: 1s - loss: 0\n",
      "Epoch 50/200\n",
      "14822/14822 [==============================] - 14s 973us/step - loss: 0.8528 - mae: 1.2600\n",
      "Epoch 51/200\n",
      "14822/14822 [==============================] - 14s 975us/step - loss: 0.9358 - mae: 1.3534\n",
      "Epoch 52/200\n",
      "14822/14822 [==============================] - 15s 985us/step - loss: 0.8202 - mae: 1.2122\n",
      "Epoch 53/200\n",
      "14822/14822 [==============================] - 14s 977us/step - loss: 0.3074 - mae: 0.63640s - loss: 0.3068 - ma\n",
      "Epoch 54/200\n",
      "14822/14822 [==============================] - 14s 973us/step - loss: 0.3752 - mae: 0.73722s - loss: 0.3730 - mae: 0.7 - ETA: 2s - loss: 0.3740 - mae: 0. - ETA:\n",
      "Epoch 55/200\n",
      "14822/14822 [==============================] - 14s 967us/step - loss: 0.5932 - mae: 0.9809\n",
      "Epoch 56/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 0.6805 - mae: 1.0591: 0s - loss: 0.6936 - mae: 1.07 - ETA: 0s - loss: 0.6895 - mae: 1\n",
      "Epoch 57/200\n",
      "14822/14822 [==============================] - 16s 1ms/step - loss: 0.3765 - mae: 0.7317\n",
      "Epoch 58/200\n",
      "14822/14822 [==============================] - 14s 978us/step - loss: 0.8858 - mae: 1.29985s - loss: 0.7866 - mae: - ETA: 5s - loss: 0.8158 - mae - ETA: 4s - loss: 0.85 - ETA: 1s - loss: 0.9\n",
      "Epoch 59/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 0.5334 - mae: 0.8876: 1s - loss: 0.547 - ETA: 0s - loss: 0.5352 - mae: 0.\n",
      "Epoch 60/200\n",
      "14822/14822 [==============================] - 14s 970us/step - loss: 0.3370 - mae: 0.6892\n",
      "Epoch 61/200\n",
      "14822/14822 [==============================] - 14s 976us/step - loss: 0.3650 - mae: 0.72380s - loss: 0.3632 - mae: 0.7\n",
      "Epoch 62/200\n",
      "14822/14822 [==============================] - 14s 972us/step - loss: 0.3878 - mae: 0.76019s - loss: 0.4022 - ETA: 9s  - ET - ETA: 2s - loss: 0.3861 - mae: - E\n",
      "Epoch 63/200\n",
      "14822/14822 [==============================] - 14s 964us/step - loss: 0.3935 - mae: 0.76690s - loss: 0.3949 - mae\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14822/14822 [==============================] - 14s 919us/step - loss: 0.3904 - mae: 0.7580\n",
      "Epoch 65/200\n",
      "14822/14822 [==============================] - 13s 889us/step - loss: 0.4844 - mae: 0.8624\n",
      "Epoch 66/200\n",
      "14822/14822 [==============================] - 13s 894us/step - loss: 0.3833 - mae: 0.7576\n",
      "Epoch 67/200\n",
      "14822/14822 [==============================] - 13s 891us/step - loss: 0.3830 - mae: 0.76423 - ETA: 1s - lo\n",
      "Epoch 68/200\n",
      "14822/14822 [==============================] - 13s 899us/step - loss: 0.3758 - mae: 0.72941s - loss: 0.3781 - mae:  - ETA: 0s - loss: 0.375\n",
      "Epoch 69/200\n",
      "14822/14822 [==============================] - 13s 903us/step - loss: 0.8579 - mae: 1.2630\n",
      "Epoch 70/200\n",
      "14822/14822 [==============================] - 13s 908us/step - loss: 0.3783 - mae: 0.70872s - loss: 0.3902 - mae: 0\n",
      "Epoch 71/200\n",
      "14822/14822 [==============================] - 13s 899us/step - loss: 0.3738 - mae: 0.7353\n",
      "Epoch 72/200\n",
      "14822/14822 [==============================] - 13s 895us/step - loss: 0.3665 - mae: 0.72910s - loss: 0.3696 - ma\n",
      "Epoch 73/200\n",
      "14822/14822 [==============================] - 13s 908us/step - loss: 0.3693 - mae: 0.7364\n",
      "Epoch 74/200\n",
      "14822/14822 [==============================] - 13s 892us/step - loss: 0.3765 - mae: 0.7389\n",
      "Epoch 75/200\n",
      "14822/14822 [==============================] - 13s 897us/step - loss: 0.3861 - mae: 0.7605\n",
      "Epoch 76/200\n",
      "14822/14822 [==============================] - 13s 910us/step - loss: 0.3630 - mae: 0.7200\n",
      "Epoch 77/200\n",
      "14822/14822 [==============================] - 13s 899us/step - loss: 0.5646 - mae: 0.9536\n",
      "Epoch 78/200\n",
      "14822/14822 [==============================] - 13s 897us/step - loss: 0.3610 - mae: 0.7213\n",
      "Epoch 79/200\n",
      "14822/14822 [==============================] - 13s 897us/step - loss: 0.3568 - mae: 0.7139\n",
      "Epoch 80/200\n",
      "14822/14822 [==============================] - 14s 935us/step - loss: 0.3691 - mae: 0.73511s - loss:\n",
      "Epoch 81/200\n",
      "14822/14822 [==============================] - 14s 939us/step - loss: 0.3658 - mae: 0.7300\n",
      "Epoch 82/200\n",
      "14822/14822 [==============================] - 14s 929us/step - loss: 0.3649 - mae: 0.7318\n",
      "Epoch 83/200\n",
      "14822/14822 [==============================] - 14s 915us/step - loss: 0.3598 - mae: 0.71820s - loss: 0.3584 -\n",
      "Epoch 84/200\n",
      "14822/14822 [==============================] - 13s 896us/step - loss: 0.3803 - mae: 0.75042s - loss: 0. - ETA: 1s - l - ETA: 0s - loss: 0.3836 - ma\n",
      "Epoch 85/200\n",
      "14822/14822 [==============================] - 13s 897us/step - loss: 0.3591 - mae: 0.7146\n",
      "Epoch 86/200\n",
      "14822/14822 [==============================] - 13s 895us/step - loss: 0.3516 - mae: 0.7044\n",
      "Epoch 87/200\n",
      "14822/14822 [==============================] - 13s 897us/step - loss: 0.3468 - mae: 0.6989\n",
      "Epoch 88/200\n",
      "14822/14822 [==============================] - 13s 898us/step - loss: 0.3638 - mae: 0.7276\n",
      "Epoch 89/200\n",
      "14822/14822 [==============================] - 14s 916us/step - loss: 0.3491 - mae: 0.7080 ETA: 3s - loss: - ETA: 2s - loss: 0.3476 - mae: 0.70 - ETA: 2s - loss: 0.3466 - mae: \n",
      "Epoch 90/200\n",
      "14822/14822 [==============================] - 13s 906us/step - loss: 0.3499 - mae: 0.70696s - loss: 0.363 - ETA: 0s - loss: 0.3546 -\n",
      "Epoch 91/200\n",
      "14822/14822 [==============================] - 14s 917us/step - loss: 0.3688 - mae: 0.72302s - loss: 0.3629 -  - ETA: 1s -\n",
      "Epoch 92/200\n",
      "14822/14822 [==============================] - 13s 910us/step - loss: 0.3616 - mae: 0.72790s - loss: 0.3659 - \n",
      "Epoch 93/200\n",
      "14822/14822 [==============================] - 14s 936us/step - loss: 0.3624 - mae: 0.71156s \n",
      "Epoch 94/200\n",
      "14822/14822 [==============================] - 13s 909us/step - loss: 0.3426 - mae: 0.6924\n",
      "Epoch 95/200\n",
      "14822/14822 [==============================] - 14s 923us/step - loss: 0.3594 - mae: 0.7078\n",
      "Epoch 96/200\n",
      "14822/14822 [==============================] - 14s 913us/step - loss: 0.3587 - mae: 0.7204\n",
      "Epoch 97/200\n",
      "14822/14822 [==============================] - 14s 917us/step - loss: 0.3455 - mae: 0.69911s -  - ETA: 0s - loss: 0.3448 - mae: 0\n",
      "Epoch 98/200\n",
      "14822/14822 [==============================] - 14s 948us/step - loss: 0.3517 - mae: 0.7086\n",
      "Epoch 99/200\n",
      "14822/14822 [==============================] - 14s 919us/step - loss: 0.3465 - mae: 0.69619s - loss: - ETA: 3s - los - ETA: 2s - loss: 0.3394 - mae: - ETA: 1s\n",
      "Epoch 100/200\n",
      "14822/14822 [==============================] - 14s 922us/step - loss: 0.3395 - mae: 0.6794\n",
      "Epoch 101/200\n",
      "14822/14822 [==============================] - 13s 908us/step - loss: 0.3614 - mae: 0.7196\n",
      "Epoch 102/200\n",
      "14822/14822 [==============================] - 14s 945us/step - loss: 0.3490 - mae: 0.70313s - loss: 0.3518 - ma - ETA: 3s - loss: 0.3523 - mae: 0 - ETA: 2s - - ETA: 1s - loss: 0\n",
      "Epoch 103/200\n",
      "14822/14822 [==============================] - 14s 920us/step - loss: 0.3478 - mae: 0.7099\n",
      "Epoch 104/200\n",
      "14822/14822 [==============================] - 14s 925us/step - loss: 0.3457 - mae: 0.70617s - loss: \n",
      "Epoch 105/200\n",
      "14822/14822 [==============================] - 14s 915us/step - loss: 0.3478 - mae: 0.70334s - - ETA: 2s - ETA: 1s - loss: 0\n",
      "Epoch 106/200\n",
      "14822/14822 [==============================] - ETA: 0s - loss: 0.3274 - mae: 0.671 - 14s 930us/step - loss: 0.3273 - mae: 0.6708\n",
      "Epoch 107/200\n",
      "14822/14822 [==============================] - 14s 918us/step - loss: 0.3400 - mae: 0.685512 - ETA: 11s - loss: 0.3633 - mae: 0.72 - ETA: 11s - loss: 0.3657 - mae - ETA\n",
      "Epoch 108/200\n",
      "14822/14822 [==============================] - 14s 925us/step - loss: 0.3556 - mae: 0.7083\n",
      "Epoch 109/200\n",
      "14822/14822 [==============================] - 14s 925us/step - loss: 0.3403 - mae: 0.6886\n",
      "Epoch 110/200\n",
      "14822/14822 [==============================] - 14s 918us/step - loss: 0.3410 - mae: 0.69267s - los - ETA: 5s - loss: 0.\n",
      "Epoch 111/200\n",
      "14822/14822 [==============================] - 14s 977us/step - loss: 0.3257 - mae: 0.67281s - loss: 0.\n",
      "Epoch 112/200\n",
      "14822/14822 [==============================] - 15s 986us/step - loss: 0.3478 - mae: 0.7017\n",
      "Epoch 113/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 0.3358 - mae: 0.6945\n",
      "Epoch 114/200\n",
      "14822/14822 [==============================] - 15s 981us/step - loss: 0.3352 - mae: 0.6865\n",
      "Epoch 115/200\n",
      "14822/14822 [==============================] - 14s 958us/step - loss: 0.3257 - mae: 0.66744s - loss: 0.3202 - mae: 0.661 - ETA: 3s  \n",
      "Epoch 116/200\n",
      "14822/14822 [==============================] - 15s 1ms/step - loss: 0.3303 - mae: 0.6723\n",
      "Epoch 117/200\n",
      "14822/14822 [==============================] - 13s 898us/step - loss: 0.3507 - mae: 0.7068\n",
      "Epoch 118/200\n",
      "14822/14822 [==============================] - 14s 966us/step - loss: 0.3196 - mae: 0.6555\n",
      "Epoch 119/200\n",
      "14822/14822 [==============================] - 14s 938us/step - loss: 0.3338 - mae: 0.6839\n",
      "Epoch 120/200\n",
      "14822/14822 [==============================] - 12s 836us/step - loss: 0.3260 - mae: 0.6602\n",
      "Epoch 121/200\n",
      "14822/14822 [==============================] - 12s 803us/step - loss: 0.3275 - mae: 0.6753\n",
      "Epoch 122/200\n",
      "14822/14822 [==============================] - 12s 840us/step - loss: 0.5582 - mae: 0.9161\n",
      "Epoch 123/200\n",
      "14822/14822 [==============================] - 13s 853us/step - loss: 0.9437 - mae: 1.3393\n",
      "Epoch 124/200\n",
      "14822/14822 [==============================] - 12s 832us/step - loss: 0.8707 - mae: 1.2877\n",
      "Epoch 125/200\n",
      "14822/14822 [==============================] - 12s 800us/step - loss: 0.2114 - mae: 0.4280\n",
      "Epoch 126/200\n",
      "14822/14822 [==============================] - 12s 809us/step - loss: 0.2310 - mae: 0.4810\n",
      "Epoch 127/200\n",
      "14822/14822 [==============================] - 12s 798us/step - loss: 0.3065 - mae: 0.6378\n",
      "Epoch 128/200\n",
      "14822/14822 [==============================] - 12s 808us/step - loss: 0.3249 - mae: 0.6739\n",
      "Epoch 129/200\n",
      "14822/14822 [==============================] - 12s 795us/step - loss: 0.3189 - mae: 0.6639\n",
      "Epoch 130/200\n",
      "14822/14822 [==============================] - 12s 793us/step - loss: 0.3251 - mae: 0.6695\n",
      "Epoch 131/200\n",
      "14822/14822 [==============================] - 12s 804us/step - loss: 0.3172 - mae: 0.6547\n",
      "Epoch 132/200\n",
      "14822/14822 [==============================] - 12s 813us/step - loss: 0.3113 - mae: 0.6461\n",
      "Epoch 133/200\n",
      "14822/14822 [==============================] - 12s 800us/step - loss: 0.3191 - mae: 0.6612\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14822/14822 [==============================] - 12s 788us/step - loss: 0.3187 - mae: 0.6572\n",
      "Epoch 135/200\n",
      "14822/14822 [==============================] - 12s 810us/step - loss: 0.3505 - mae: 0.6936\n",
      "Epoch 136/200\n",
      "14822/14822 [==============================] - 12s 825us/step - loss: 0.3206 - mae: 0.6626\n",
      "Epoch 137/200\n",
      "14822/14822 [==============================] - 12s 793us/step - loss: 0.3124 - mae: 0.6475\n",
      "Epoch 138/200\n",
      "14822/14822 [==============================] - 12s 797us/step - loss: 0.3204 - mae: 0.6608\n",
      "Epoch 139/200\n",
      "14822/14822 [==============================] - 13s 846us/step - loss: 0.3136 - mae: 0.6558\n",
      "Epoch 140/200\n",
      "14822/14822 [==============================] - 13s 871us/step - loss: 0.3279 - mae: 0.6745\n",
      "Epoch 141/200\n",
      "14822/14822 [==============================] - 12s 819us/step - loss: 0.3339 - mae: 0.6785\n",
      "Epoch 142/200\n",
      "14822/14822 [==============================] - 12s 797us/step - loss: 0.2985 - mae: 0.6243\n",
      "Epoch 143/200\n",
      "14822/14822 [==============================] - 12s 803us/step - loss: 0.3186 - mae: 0.6471\n",
      "Epoch 144/200\n",
      "14822/14822 [==============================] - 12s 812us/step - loss: 0.3223 - mae: 0.6599\n",
      "Epoch 145/200\n",
      "14822/14822 [==============================] - 12s 805us/step - loss: 0.3213 - mae: 0.6639\n",
      "Epoch 146/200\n",
      "14822/14822 [==============================] - 12s 812us/step - loss: 0.3054 - mae: 0.6340\n",
      "Epoch 147/200\n",
      "14822/14822 [==============================] - 12s 808us/step - loss: 0.3464 - mae: 0.6943\n",
      "Epoch 148/200\n",
      "14822/14822 [==============================] - 12s 815us/step - loss: 0.3042 - mae: 0.6339\n",
      "Epoch 149/200\n",
      "14822/14822 [==============================] - 12s 834us/step - loss: 0.3227 - mae: 0.65361s - loss:\n",
      "Epoch 150/200\n",
      "14822/14822 [==============================] - 13s 861us/step - loss: 0.3247 - mae: 0.6605\n",
      "Epoch 151/200\n",
      "14822/14822 [==============================] - 12s 839us/step - loss: 0.3078 - mae: 0.6431\n",
      "Epoch 152/200\n",
      "14822/14822 [==============================] - 12s 836us/step - loss: 0.3139 - mae: 0.6455\n",
      "Epoch 153/200\n",
      "14822/14822 [==============================] - 12s 809us/step - loss: 0.3077 - mae: 0.6352\n",
      "Epoch 154/200\n",
      "14822/14822 [==============================] - 12s 833us/step - loss: 0.3040 - mae: 0.62453s - loss: 0. - ETA: 2s - loss: 0.29 - ETA:\n",
      "Epoch 155/200\n",
      "14822/14822 [==============================] - 12s 794us/step - loss: 0.3215 - mae: 0.66160s - loss: 0.3274 \n",
      "Epoch 156/200\n",
      "14822/14822 [==============================] - 12s 830us/step - loss: 0.3081 - mae: 0.6418\n",
      "Epoch 157/200\n",
      "14822/14822 [==============================] - 12s 812us/step - loss: 0.3210 - mae: 0.6619\n",
      "Epoch 158/200\n",
      "14822/14822 [==============================] - 12s 801us/step - loss: 0.3027 - mae: 0.6263\n",
      "Epoch 159/200\n",
      "14822/14822 [==============================] - 12s 786us/step - loss: 0.2984 - mae: 0.6276\n",
      "Epoch 160/200\n",
      "14822/14822 [==============================] - 12s 818us/step - loss: 0.3115 - mae: 0.63272s -\n",
      "Epoch 161/200\n",
      "14822/14822 [==============================] - 12s 805us/step - loss: 0.3311 - mae: 0.6725\n",
      "Epoch 162/200\n",
      "14822/14822 [==============================] - 12s 803us/step - loss: 1.2255 - mae: 1.64890s - loss: 1.2238 - mae: 1.647\n",
      "Epoch 163/200\n",
      "14822/14822 [==============================] - 12s 798us/step - loss: 0.8101 - mae: 1.2259\n",
      "Epoch 164/200\n",
      "14822/14822 [==============================] - 13s 844us/step - loss: 0.2106 - mae: 0.4255\n",
      "Epoch 165/200\n",
      "14822/14822 [==============================] - 12s 829us/step - loss: 0.2104 - mae: 0.4221\n",
      "Epoch 166/200\n",
      "14822/14822 [==============================] - 12s 818us/step - loss: 0.2719 - mae: 0.5745\n",
      "Epoch 167/200\n",
      "14822/14822 [==============================] - 12s 803us/step - loss: 0.2842 - mae: 0.5975\n",
      "Epoch 168/200\n",
      "14822/14822 [==============================] - 12s 826us/step - loss: 0.3138 - mae: 0.6531\n",
      "Epoch 169/200\n",
      "14822/14822 [==============================] - 12s 822us/step - loss: 0.2939 - mae: 0.61890s - loss: 0.2940 - mae: 0.61\n",
      "Epoch 170/200\n",
      "14822/14822 [==============================] - 12s 806us/step - loss: 0.3096 - mae: 0.6364\n",
      "Epoch 171/200\n",
      "14822/14822 [==============================] - 12s 809us/step - loss: 0.2971 - mae: 0.6216\n",
      "Epoch 172/200\n",
      "14822/14822 [==============================] - 12s 817us/step - loss: 0.2980 - mae: 0.6226\n",
      "Epoch 173/200\n",
      "14822/14822 [==============================] - 12s 817us/step - loss: 0.3048 - mae: 0.63550s - loss: 0.3062 - mae: \n",
      "Epoch 174/200\n",
      "14822/14822 [==============================] - 12s 840us/step - loss: 0.3024 - mae: 0.6267\n",
      "Epoch 175/200\n",
      "14822/14822 [==============================] - 12s 807us/step - loss: 0.2989 - mae: 0.6239\n",
      "Epoch 176/200\n",
      "14822/14822 [==============================] - 12s 825us/step - loss: 0.3038 - mae: 0.6372\n",
      "Epoch 177/200\n",
      "14822/14822 [==============================] - 12s 828us/step - loss: 0.2980 - mae: 0.62891s - los\n",
      "Epoch 178/200\n",
      "14822/14822 [==============================] - 12s 811us/step - loss: 0.3143 - mae: 0.6306\n",
      "Epoch 179/200\n",
      "14822/14822 [==============================] - 12s 812us/step - loss: 0.3094 - mae: 0.6428\n",
      "Epoch 180/200\n",
      "14822/14822 [==============================] - 12s 825us/step - loss: 0.3013 - mae: 0.6277\n",
      "Epoch 181/200\n",
      "14822/14822 [==============================] - 12s 826us/step - loss: 0.3028 - mae: 0.6286\n",
      "Epoch 182/200\n",
      "14822/14822 [==============================] - 12s 806us/step - loss: 0.2891 - mae: 0.6074\n",
      "Epoch 183/200\n",
      "14822/14822 [==============================] - 12s 803us/step - loss: 0.3200 - mae: 0.6579\n",
      "Epoch 184/200\n",
      "14822/14822 [==============================] - 12s 808us/step - loss: 0.2812 - mae: 0.5883\n",
      "Epoch 185/200\n",
      "14822/14822 [==============================] - 12s 825us/step - loss: 0.3074 - mae: 0.6377\n",
      "Epoch 186/200\n",
      "14822/14822 [==============================] - 12s 825us/step - loss: 0.2954 - mae: 0.6190\n",
      "Epoch 187/200\n",
      "14822/14822 [==============================] - 12s 810us/step - loss: 0.2882 - mae: 0.6054\n",
      "Epoch 188/200\n",
      "14822/14822 [==============================] - 12s 801us/step - loss: 0.2999 - mae: 0.6327\n",
      "Epoch 189/200\n",
      "14822/14822 [==============================] - 12s 835us/step - loss: 0.3080 - mae: 0.6350\n",
      "Epoch 190/200\n",
      "14822/14822 [==============================] - 12s 817us/step - loss: 0.2913 - mae: 0.6122\n",
      "Epoch 191/200\n",
      "14822/14822 [==============================] - 12s 806us/step - loss: 0.3085 - mae: 0.6276\n",
      "Epoch 192/200\n",
      "14822/14822 [==============================] - 12s 820us/step - loss: 0.2866 - mae: 0.6039\n",
      "Epoch 193/200\n",
      "14822/14822 [==============================] - 12s 827us/step - loss: 0.2939 - mae: 0.6107\n",
      "Epoch 194/200\n",
      "14822/14822 [==============================] - 12s 813us/step - loss: 0.2904 - mae: 0.6165\n",
      "Epoch 195/200\n",
      "14822/14822 [==============================] - 12s 809us/step - loss: 0.3001 - mae: 0.6239\n",
      "Epoch 196/200\n",
      "14822/14822 [==============================] - 12s 814us/step - loss: 0.2898 - mae: 0.6042\n",
      "Epoch 197/200\n",
      "14822/14822 [==============================] - 12s 826us/step - loss: 0.4040 - mae: 0.73140s - loss: 0.3486 - mae\n",
      "Epoch 198/200\n",
      "14822/14822 [==============================] - 12s 826us/step - loss: 0.2760 - mae: 0.5765\n",
      "Epoch 199/200\n",
      "14822/14822 [==============================] - 13s 855us/step - loss: 0.2882 - mae: 0.6121\n",
      "Epoch 200/200\n",
      "14822/14822 [==============================] - 12s 804us/step - loss: 0.2818 - mae: 0.5930\n",
      "\n",
      "Saving model weights to model_logs\\118_nn1_8H_PSSE_epoch_200.h5\n",
      "3706/3706 [==============================] - 1s 313us/step\n",
      "\n",
      "mae: 80.76%\n",
      "3706\n",
      "\n",
      " distance from the true states in terms of \\|\\|_2: 0.2306%\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "SEED=1234\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(SEED)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from model import *\n",
    "\n",
    "# configure args\n",
    "tf.set_random_seed(SEED)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "# data loading part\n",
    "caseNo = 118\n",
    "weight_4_mag = 100\n",
    "weight_4_ang = 1#2*math.pi/360\n",
    "\n",
    "psse_data = scipy.io.loadmat('dist2_118FASE_data.mat')\n",
    "print(psse_data['inputs'].shape, psse_data['labels'].shape)\n",
    "\n",
    "data_x = psse_data['inputs']\n",
    "data_y = psse_data['labels']\n",
    "\n",
    "# scale the mags,\n",
    "data_y[0:caseNo,:] = weight_4_mag*data_y[0:caseNo,:]\n",
    "data_y[caseNo:,:] = weight_4_ang*data_y[caseNo:,:]\n",
    "\n",
    "\n",
    "# seperate them into training 80%, test 20%\n",
    "split_train = int(0.8*psse_data['inputs'].shape[1])\n",
    "split_val = psse_data['inputs'].shape[1] - split_train #int(0.25*psse_data['inputs'].shape[1])\n",
    "train_x = np.transpose(data_x[:, :split_train])\n",
    "train_y = np.transpose(data_y[:, :split_train])\n",
    "val_x   = np.transpose(data_x[:, split_train:split_train+split_val])\n",
    "val_y   = np.transpose(data_y[:, split_train:split_train+split_val])\n",
    "test_x  = np.transpose(data_x[:, split_train+split_val:])\n",
    "test_y  = np.transpose(data_y[:, split_train+split_val:])\n",
    "\n",
    "print(train_x.shape, val_x.shape)\n",
    "#Train the model\n",
    "input_shape = (train_x.shape[1],)\n",
    "\n",
    "epoch_num = 200\n",
    "psse_model = nn1_8H_psse(input_shape, train_y.shape[1])\n",
    "psse_model.fit(train_x, train_y, epochs=epoch_num, batch_size=64)\n",
    "\n",
    "save_file = '_'.join([str(caseNo), 'nn1_8H_PSSE',\n",
    "                      'epoch', str(epoch_num)]) + '.h5'\n",
    "\n",
    "if not os.path.exists('model_logs'):\n",
    "    os.makedirs('model_logs')\n",
    "save_path = os.path.join('model_logs', save_file)\n",
    "print('\\nSaving model weights to {:s}'.format(save_path))\n",
    "psse_model.save_weights(save_path)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "K.set_learning_phase(0)\n",
    "val_predic = psse_model.predict(val_x)\n",
    "scores = psse_model.evaluate(val_x, val_y)\n",
    "print(\"\\n%s: %.2f%%\" % (psse_model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "#the self.defined distance metric since, to access the distance between predicted and the true\n",
    "print(val_y.shape[0])\n",
    "test_no = 3706\n",
    "def rmse(val_predic, val_y, voltage_distance = np.zeros((test_no,caseNo)), voltage_norm = np.zeros((test_no,1))):\n",
    "    for i in range(test_no):\n",
    "        for j in range(caseNo):\n",
    "            predic_r, predic_i = (1/weight_4_mag)* val_predic[i, j]*math.cos(val_predic[i, j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_predic[i,j]*math.sin(val_predic[i, j+caseNo]*2*math.pi/360)\n",
    "            val_r, val_i = (1/weight_4_mag)*val_y[i,j]*math.cos(val_y[i,j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_y[i][j]*math.sin(val_y[i][j+caseNo]*2*math.pi/360)\n",
    "            voltage_distance[i,j] = (predic_r-val_r)**2 + (predic_i-val_i)**2\n",
    "            #print(i, j, val_predic[i, j], val_predic[i, j+caseNo], val_y[i,j], val_y[i,j+caseNo])\n",
    "        voltage_norm[i,] = (1/caseNo)*np.sqrt(np.sum(voltage_distance[i,:]))\n",
    "    return np.mean(voltage_norm) *100\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(val_predic, val_y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3706, 236)\n",
      "(14822, 490)\n",
      "(3706, 490)\n",
      "--- 6.225186586380005 seconds ---\n",
      "\n",
      " distance from the true states in terms of \\|\\|_2: 0.0122%\n",
      "\n",
      " distance from the true states in terms of \\|\\|_2: 0.1588%\n",
      "\n",
      " distance from the true states in terms of \\|\\|_2: 0.2306%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'hold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0ce930015ce2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_bus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_bus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mweight_4_mag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimeslot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_bus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mend_bus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# here we have start_bus+1 is due to that in our paper, index starts 1 while python starts 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_bus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_bus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mweight_4_mag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mlav_predicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimeslot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_bus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mend_bus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'--'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'hold'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "SEED = 1234\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "np.random.seed(SEED)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from model import *\n",
    "\n",
    "# configure args\n",
    "tf.set_random_seed(SEED)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "caseNo = 118\n",
    "weight_4_mag = 100\n",
    "weight_4_ang = 1#2*math.pi/360\n",
    "\n",
    "# data loading part\n",
    "psse_data = scipy.io.loadmat('dist2_118FASE_data.mat')\n",
    "matlab_predicts = scipy.io.loadmat('118_bus_GStest_err.mat')\n",
    "gs_predicts = matlab_predicts['GS_voltage']\n",
    "gs_predicts = np.transpose(gs_predicts)\n",
    "print(gs_predicts.shape)\n",
    "data_x = psse_data['inputs']\n",
    "data_y = psse_data['labels']\n",
    "\n",
    "# scale the mags,\n",
    "data_y[0:caseNo,:] = weight_4_mag*data_y[0:caseNo,:]\n",
    "data_y[caseNo:,:] = weight_4_ang*data_y[caseNo:,:]\n",
    "# seperate them into training 80%, test 20%\n",
    "split_train = int(0.8*psse_data['inputs'].shape[1])\n",
    "split_val = psse_data['inputs'].shape[1] - split_train #int(0.25*psse_data['inputs'].shape[1])\n",
    "train_x = np.transpose(data_x[:, :split_train])\n",
    "train_y = np.transpose(data_y[:, :split_train])\n",
    "val_x   = np.transpose(data_x[:, split_train:split_train+split_val])\n",
    "val_y   = np.transpose(data_y[:, split_train:split_train+split_val])\n",
    "test_x  = np.transpose(data_x[:, split_train+split_val:])\n",
    "test_y  = np.transpose(data_y[:, split_train+split_val:])\n",
    "\n",
    "print(train_x.shape)\n",
    "print(val_x.shape)\n",
    "\n",
    "#Train the model\n",
    "input_shape = (train_x.shape[1],)\n",
    "\n",
    "start_time = time.time()\n",
    "lav_weights = 'model_logs/118_lav_PSSE_epoch_200.h5'\n",
    "nn1_6H_weights = 'model_logs/118_nn1_6H_PSSE_epoch_200.h5'\n",
    "nn1_8H_weights = 'model_logs/118_nn1_8H_PSSE_epoch_200.h5'\n",
    "\n",
    "lav_model =  lav_psse(input_shape, train_y.shape[1], weights=lav_weights)\n",
    "nn1_6H_model =  nn1_psse(input_shape, train_y.shape[1], weights=nn1_6H_weights)\n",
    "nn1_8H_model =  nn1_8H_psse(input_shape, train_y.shape[1], weights=nn1_8H_weights)\n",
    "\n",
    "#train_lav_predicts = lav_model.predict(train_x)\n",
    "lav_predicts = lav_model.predict(val_x)\n",
    "NN6H_predicts = nn1_6H_model.predict(val_x)\n",
    "NN8H_predicts = nn1_8H_model.predict(val_x)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "val_predic = lav_predicts\n",
    "test_no = 3706\n",
    "def rmse(val_predic, val_y, voltage_distance = np.zeros((test_no,caseNo)), voltage_norm = np.zeros((test_no,1))):\n",
    "    for i in range(test_no):\n",
    "        for j in range(caseNo):\n",
    "            predic_r, predic_i = (1/weight_4_mag)* val_predic[i, j]*math.cos(val_predic[i, j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_predic[i,j]*math.sin(val_predic[i, j+caseNo]*2*math.pi/360)\n",
    "            val_r, val_i = (1/weight_4_mag)*val_y[i,j]*math.cos(val_y[i,j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_y[i][j]*math.sin(val_y[i][j+caseNo]*2*math.pi/360)\n",
    "            voltage_distance[i,j] = (predic_r-val_r)**2 + (predic_i-val_i)**2\n",
    "            #print(i, j, val_predic[i, j], val_predic[i, j+caseNo], val_y[i,j], val_y[i,j+caseNo])\n",
    "        voltage_norm[i,] = (1/caseNo)*np.sqrt(np.sum(voltage_distance[i,:]))\n",
    "    return np.mean(voltage_norm) *100\n",
    "\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(lav_predicts, val_y))\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(NN6H_predicts, val_y))\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(NN8H_predicts, val_y))\n",
    "\n",
    "fig_num = 0\n",
    "plt.figure(fig_num)\n",
    "fig_num += 1\n",
    "\n",
    "busNo = caseNo\n",
    "start_bus, end_bus = 0, 50\n",
    "timeslot = 999\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(range(start_bus+1, end_bus+1), (1/weight_4_mag)* val_y[timeslot][start_bus: end_bus], color='k', marker='o') # here we have start_bus+1 is due to that in our paper, index starts 1 while python starts 0\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), (1/weight_4_mag)* lav_predicts[timeslot][start_bus: end_bus], linestyle= '--',  color='r', marker='s')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), (1/weight_4_mag)* NN6H_predicts[timeslot][start_bus: end_bus],linestyle= '-.', color='y')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), (1/weight_4_mag)* NN8H_predicts[timeslot][start_bus: end_bus] , color='b')\n",
    "linestyle= '-.'\n",
    "plt.ylabel('Voltage mag. (p.u.)')\n",
    "plt.title('Voltages for test instance ' + str(timeslot+1))\n",
    "axes = plt.gca()\n",
    "axes.set_xticks(list(range(start_bus+1, end_bus+1, 10)))\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(range(start_bus+1, end_bus+1), val_y[timeslot][start_bus+ busNo: end_bus+ busNo], color='k',  marker='o')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), lav_predicts[timeslot][start_bus+ busNo: end_bus+ busNo], linestyle= '--', color='r',  marker='s')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), NN6H_predicts[timeslot][start_bus+ busNo: end_bus+ busNo], linestyle= '-.', color='y')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), NN8H_predicts[timeslot][start_bus+ busNo: end_bus+ busNo], color='b')\n",
    "plt.ylabel('Voltage angle (degree)')\n",
    "plt.xlabel('Bus number')\n",
    "plt.legend( ['Ground truth', 'Prox-linear net', '6-layer FNN', '8-layer FNN'], loc=3, prop={'size': 8})\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xticks(list(range(start_bus+1, end_bus+1, 10)))\n",
    "\n",
    "\n",
    "def plt_bus(busShow = 100, x_step = 5, start = 999, end = 1050, fig_num = 0):\n",
    "    plt.figure(fig_num)\n",
    "# this is for a certain bus across different time slots\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    plt.plot(range(start+1, end+1), (1/weight_4_mag)* val_y[start: end, busShow], color='k',  marker='o')\n",
    "    plt.hold\n",
    "    plt.plot(range(start+1, end+1), (1/weight_4_mag)* lav_predicts[start: end, busShow], linestyle= '--',  color='r',  marker='s')\n",
    "    plt.hold\n",
    "    plt.plot(range(start+1, end+1), (1/weight_4_mag)* NN6H_predicts[start: end, busShow], linestyle= '-.', color='y')\n",
    "    plt.hold\n",
    "    plt.plot(range(start+1, end+1), (1/weight_4_mag)* NN8H_predicts[start: end, busShow], color='b')\n",
    "    #plt.hold\n",
    "    #plt.plot(range(start+1, end+1), gs_predicts[start: end, busShow], color='c',linestyle= ':')\n",
    "\n",
    "    ax1.set_xticks(list(range(start+1, end+1, x_step)))\n",
    "    plt.ylabel('Voltage mag. (p.u.)')\n",
    "    plt.title('Voltages for bus ' + str(busShow))\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(range(start+1, end+1), val_y[start: end, busShow + busNo], color='k',  marker='o')\n",
    "    plt.hold\n",
    "    plt.plot(range(start+1, end+1), lav_predicts[start: end, busShow + busNo], linestyle= '--', color='r',  marker='s')\n",
    "    plt.hold(1)\n",
    "    plt.plot(range(start+1, end+1), NN6H_predicts[start: end, busShow + busNo],  linestyle= '-.', color='y')\n",
    "    plt.hold(1)\n",
    "    plt.plot(range(start+1, end+1), NN8H_predicts[start: end, busShow + busNo], color='b')\n",
    "    plt.legend( ['Ground truth', 'Prox-linear net', '6-layer FNN', '8-layer FNN'], loc=3, prop={'size': 8})\n",
    "\n",
    "    #plt.hold\n",
    "    #plt.plot(range(start+1, end+1),  gs_predicts[start: end, busShow+ busNo], color='c',linestyle= ':')\n",
    "\n",
    "    plt.ylabel('Voltage angle (degree)')\n",
    "    plt.xlabel('Test instance index')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xticks(list(range(start+1, end+1, x_step)))\n",
    "\n",
    "bus_list = [50, 80, 100, 105]\n",
    "for i, busShow in enumerate(bus_list):\n",
    "    plt_bus(busShow = busShow, fig_num = i + 1)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3706, 236)\n",
      "(14822, 490)\n",
      "(3706, 490)\n",
      "WARNING:tensorflow:From C:\\Users\\Akash Sharma\\Desktop\\Final Year Project\\PSSE-via-DNNs-master\\model.py:25: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Akash Sharma\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "--- 4.945030927658081 seconds ---\n",
      "\n",
      " distance from the true states in terms of \\|\\|_2: 0.0122%\n",
      "\n",
      " distance from the true states in terms of \\|\\|_2: 0.1588%\n",
      "\n",
      " distance from the true states in terms of \\|\\|_2: 0.2306%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'hold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cf8fff6865b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_bus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_bus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mweight_4_mag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimeslot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_bus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mend_bus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# here we have start_bus+1 is due to that in our paper, index starts 1 while python starts 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_bus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_bus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mweight_4_mag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mlav_predicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimeslot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_bus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mend_bus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'--'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'hold'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "SEED = 1234\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "np.random.seed(SEED)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from model import *\n",
    "\n",
    "# configure args\n",
    "tf.set_random_seed(SEED)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "caseNo = 118\n",
    "weight_4_mag = 100\n",
    "weight_4_ang = 1#2*math.pi/360\n",
    "\n",
    "# data loading part\n",
    "psse_data = scipy.io.loadmat('dist2_118FASE_data.mat')\n",
    "matlab_predicts = scipy.io.loadmat('118_bus_GStest_err.mat')\n",
    "gs_predicts = matlab_predicts['GS_voltage']\n",
    "gs_predicts = np.transpose(gs_predicts)\n",
    "print(gs_predicts.shape)\n",
    "data_x = psse_data['inputs']\n",
    "data_y = psse_data['labels']\n",
    "\n",
    "# scale the mags,\n",
    "data_y[0:caseNo,:] = weight_4_mag*data_y[0:caseNo,:]\n",
    "data_y[caseNo:,:] = weight_4_ang*data_y[caseNo:,:]\n",
    "# seperate them into training 80%, test 20%\n",
    "split_train = int(0.8*psse_data['inputs'].shape[1])\n",
    "split_val = psse_data['inputs'].shape[1] - split_train #int(0.25*psse_data['inputs'].shape[1])\n",
    "train_x = np.transpose(data_x[:, :split_train])\n",
    "train_y = np.transpose(data_y[:, :split_train])\n",
    "val_x   = np.transpose(data_x[:, split_train:split_train+split_val])\n",
    "val_y   = np.transpose(data_y[:, split_train:split_train+split_val])\n",
    "test_x  = np.transpose(data_x[:, split_train+split_val:])\n",
    "test_y  = np.transpose(data_y[:, split_train+split_val:])\n",
    "\n",
    "print(train_x.shape)\n",
    "print(val_x.shape)\n",
    "\n",
    "#Train the model\n",
    "input_shape = (train_x.shape[1],)\n",
    "\n",
    "start_time = time.time()\n",
    "lav_weights = 'model_logs/118_lav_PSSE_epoch_200.h5'\n",
    "nn1_6H_weights = 'model_logs/118_nn1_6H_PSSE_epoch_200.h5'\n",
    "nn1_8H_weights = 'model_logs/118_nn1_8H_PSSE_epoch_200.h5'\n",
    "\n",
    "lav_model =  lav_psse(input_shape, train_y.shape[1], weights=lav_weights)\n",
    "nn1_6H_model =  nn1_psse(input_shape, train_y.shape[1], weights=nn1_6H_weights)\n",
    "nn1_8H_model =  nn1_8H_psse(input_shape, train_y.shape[1], weights=nn1_8H_weights)\n",
    "\n",
    "#train_lav_predicts = lav_model.predict(train_x)\n",
    "lav_predicts = lav_model.predict(val_x)\n",
    "NN6H_predicts = nn1_6H_model.predict(val_x)\n",
    "NN8H_predicts = nn1_8H_model.predict(val_x)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "val_predic = lav_predicts\n",
    "test_no = 3706\n",
    "def rmse(val_predic, val_y, voltage_distance = np.zeros((test_no,caseNo)), voltage_norm = np.zeros((test_no,1))):\n",
    "    for i in range(test_no):\n",
    "        for j in range(caseNo):\n",
    "            predic_r, predic_i = (1/weight_4_mag)* val_predic[i, j]*math.cos(val_predic[i, j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_predic[i,j]*math.sin(val_predic[i, j+caseNo]*2*math.pi/360)\n",
    "            val_r, val_i = (1/weight_4_mag)*val_y[i,j]*math.cos(val_y[i,j+caseNo]*2*math.pi/360), (1/weight_4_mag)*val_y[i][j]*math.sin(val_y[i][j+caseNo]*2*math.pi/360)\n",
    "            voltage_distance[i,j] = (predic_r-val_r)**2 + (predic_i-val_i)**2\n",
    "            #print(i, j, val_predic[i, j], val_predic[i, j+caseNo], val_y[i,j], val_y[i,j+caseNo])\n",
    "        voltage_norm[i,] = (1/caseNo)*np.sqrt(np.sum(voltage_distance[i,:]))\n",
    "    return np.mean(voltage_norm) *100\n",
    "\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(lav_predicts, val_y))\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(NN6H_predicts, val_y))\n",
    "print(\"\\n distance from the true states in terms of \\|\\|_2: %.4f%%\" % rmse(NN8H_predicts, val_y))\n",
    "\n",
    "fig_num = 0\n",
    "plt.figure(fig_num)\n",
    "fig_num += 1\n",
    "\n",
    "busNo = caseNo\n",
    "start_bus, end_bus = 0, 50\n",
    "timeslot = 999\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(range(start_bus+1, end_bus+1), (1/weight_4_mag)* val_y[timeslot][start_bus: end_bus], color='k', marker='o') # here we have start_bus+1 is due to that in our paper, index starts 1 while python starts 0\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), (1/weight_4_mag)* lav_predicts[timeslot][start_bus: end_bus], linestyle= '--',  color='r', marker='s')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), (1/weight_4_mag)* NN6H_predicts[timeslot][start_bus: end_bus],linestyle= '-.', color='y')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), (1/weight_4_mag)* NN8H_predicts[timeslot][start_bus: end_bus] , color='b')\n",
    "linestyle= '-.'\n",
    "plt.ylabel('Voltage mag. (p.u.)')\n",
    "plt.title('Voltages for test instance ' + str(timeslot+1))\n",
    "axes = plt.gca()\n",
    "axes.set_xticks(list(range(start_bus+1, end_bus+1, 10)))\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(range(start_bus+1, end_bus+1), val_y[timeslot][start_bus+ busNo: end_bus+ busNo], color='k',  marker='o')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), lav_predicts[timeslot][start_bus+ busNo: end_bus+ busNo], linestyle= '--', color='r',  marker='s')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), NN6H_predicts[timeslot][start_bus+ busNo: end_bus+ busNo], linestyle= '-.', color='y')\n",
    "plt.hold\n",
    "plt.plot(range(start_bus+1, end_bus+1), NN8H_predicts[timeslot][start_bus+ busNo: end_bus+ busNo], color='b')\n",
    "plt.ylabel('Voltage angle (degree)')\n",
    "plt.xlabel('Bus number')\n",
    "plt.legend( ['Ground truth', 'Prox-linear net', '6-layer FNN', '8-layer FNN'], loc=3, prop={'size': 8})\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xticks(list(range(start_bus+1, end_bus+1, 10)))\n",
    "\n",
    "\n",
    "def plt_bus(busShow = 100, x_step = 5, start = 999, end = 1050, fig_num = 0):\n",
    "    plt.figure(fig_num)\n",
    "# this is for a certain bus across different time slots\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    plt.plot(range(start+1, end+1), (1/weight_4_mag)* val_y[start: end, busShow], color='k',  marker='o')\n",
    "    plt.hold\n",
    "    plt.plot(range(start+1, end+1), (1/weight_4_mag)* lav_predicts[start: end, busShow], linestyle= '--',  color='r',  marker='s')\n",
    "    plt.hold\n",
    "    plt.plot(range(start+1, end+1), (1/weight_4_mag)* NN6H_predicts[start: end, busShow], linestyle= '-.', color='y')\n",
    "    plt.hold\n",
    "    plt.plot(range(start+1, end+1), (1/weight_4_mag)* NN8H_predicts[start: end, busShow], color='b')\n",
    "    #plt.hold\n",
    "    #plt.plot(range(start+1, end+1), gs_predicts[start: end, busShow], color='c',linestyle= ':')\n",
    "\n",
    "    ax1.set_xticks(list(range(start+1, end+1, x_step)))\n",
    "    plt.ylabel('Voltage mag. (p.u.)')\n",
    "    plt.title('Voltages for bus ' + str(busShow))\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(range(start+1, end+1), val_y[start: end, busShow + busNo], color='k',  marker='o')\n",
    "    plt.plot(range(start+1, end+1), lav_predicts[start: end, busShow + busNo], linestyle= '--', color='r',  marker='s')\n",
    "    plt.plot(range(start+1, end+1), NN6H_predicts[start: end, busShow + busNo],  linestyle= '-.', color='y')\n",
    "    plt.plot(range(start+1, end+1), NN8H_predicts[start: end, busShow + busNo], color='b')\n",
    "    plt.legend( ['Ground truth', 'Prox-linear net', '6-layer FNN', '8-layer FNN'], loc=3, prop={'size': 8})\n",
    "\n",
    "    #plt.hold\n",
    "    #plt.plot(range(start+1, end+1),  gs_predicts[start: end, busShow+ busNo], color='c',linestyle= ':')\n",
    "\n",
    "    plt.ylabel('Voltage angle (degree)')\n",
    "    plt.xlabel('Test instance index')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xticks(list(range(start+1, end+1, x_step)))\n",
    "\n",
    "bus_list = [50, 80, 100, 105]\n",
    "for i, busShow in enumerate(bus_list):\n",
    "    plt_bus(busShow = busShow, fig_num = i + 1)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
